// scripts/make-products.ts
// Build public/products.v1.json and a CLIP embedding index (builtIndex.ts)
// Usage: npx tsx scripts/make-products.ts --limit=120

import 'dotenv/config';
import fs from 'node:fs/promises';
import path from 'node:path';
import { fileURLToPath } from 'node:url';
import { pipeline } from '@xenova/transformers';

// ----- config from CLI -----
const argv = Object.fromEntries(
  process.argv.slice(2).map((a) => {
    const [k, v] = a.split('=');
    return [k.replace(/^--/, ''), v ?? ''];
  })
);
const LIMIT = Number(argv.limit ?? 120);

// ----- dataset -----
type Product = { id: string; name: string; category: string; image: string };
// IMPORTANT: this import must point to your actual data file:
import { PRODUCTS } from '../src/data/products.ts';

const ALLOWED = new Set([
  'Bags',
  'Shoes',
  'Sunglasses',
  'Watches',
  'Chairs',
  'Jackets',
  'Shirts',
  'Dresses',
  'Laptops',
  'Phones',
]);

const filtered: Product[] = PRODUCTS.filter(p => ALLOWED.has(p.category)).slice(0, LIMIT);
if (filtered.length === 0) {
  console.error('No items after filtering. Check categories or data import.');
  process.exit(1);
}

// ----- embeddings -----
async function computeEmbeddings(items: Product[]) {
  const extractor = await pipeline('image-feature-extraction', 'Xenova/clip-vit-base-patch32');

  const out: number[][] = [];
  const batch = 4; // simple concurrency
  for (let i = 0; i < items.length; i += batch) {
    const slice = items.slice(i, i + batch);
    const embs = await Promise.all(
      slice.map(async (item) => {
        const r: any = await extractor(item.image, { pooling: 'mean', normalize: true });
        // r.data is a Float32Array
        return Array.from(r.data as Float32Array);
      })
    );
    out.push(...embs);
    process.stdout.write(`\rEmbedded ${Math.min(i + batch, items.length)}/${items.length}`);
  }
  process.stdout.write('\n');
  return out;
}

// ----- write files -----
async function writeCatalogFile(items: Product[]) {
  const dest = path.resolve(rootDir(), 'public', 'products.v1.json');
  await fs.writeFile(dest, JSON.stringify(items, null, 2));
  console.log(`✓ Wrote ${items.length} items -> public/products.v1.json`);
}

async function writeIndexFile(items: Product[], embeddings: number[][]) {
  const dim = embeddings[0]?.length ?? 0;
  const ids = items.map((x) => x.id);

  const ts = `// AUTO-GENERATED by scripts/make-products.ts — do not edit.
export type CatalogItem = { id: string; name: string; category: string; image: string };

export const CATALOG: CatalogItem[] = ${JSON.stringify(items, null, 2)} as const;

export const INDEX = {
  dim: ${dim},
  ids: ${JSON.stringify(ids)},
  embeddings: ${JSON.stringify(embeddings)}
} as const;
`;

  const dest = path.resolve(rootDir(), 'builtIndex.ts'); // keep name in repo root
  await fs.writeFile(dest, ts);
  console.log(`✓ Wrote embedding index -> builtIndex.ts (dim=${dim}, rows=${embeddings.length})`);
}

function rootDir() {
  const __filename = fileURLToPath(import.meta.url);
  const __dirname = path.dirname(__filename);
  return path.resolve(__dirname, '..');
}

(async () => {
  console.log(`Building catalog (limit=${LIMIT}) from src/data/products.ts`);
  await writeCatalogFile(filtered);
  const embeddings = await computeEmbeddings(filtered);
  await writeIndexFile(filtered, embeddings);
  console.log('✅ Done.');
})();